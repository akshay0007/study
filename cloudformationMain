aws cloud formation provide helper scirpt for deployment into ec2

amazon ec2==>
 cfn-init==>installaiton and service start up
 cfn-get-metadata->retreive all metadata .paths etc
 cfn-signal->synch resource
 cfn-hup->custom hup


Resources:{
 WebServer:{
 Type:AWS::EC2::Instance,
 MetaData:{}
 AWS::CloudFormation::Init:{
   config:{
	yum:{
	  mysql:{}
	  php:{}
		}

	}
}
}
sources:{
 /var/www/html:""
}
}


httpd==>httpDemon
 
like 
mysqlId:{
enabled:true,//start at time of boot system
ensureRunning:true//running at the time of cloudformation init
}
etc..

code in yaml and json=>deployed local or from s3 =>create stack 	using console cli=>stack and resources are provisioned 

continous intergation=>delivery=>deployment
source
build
test
promote

validate syntex::
cfn-lint
cfn_nag

TestCat test your intergation tests

WebSg:{(websecurity)
Type:AWS::EC2::SecuirtyGroup,
properties:{

}

}

automation of cloud.
networking,
infra(load balancer,instance),
IAM(user acc.,permission group,and prrivilages),
custom(it is possible to custom resources)


Taxonomy :Nouns::
templetes:: json/yaml(content and description)
stacks:: instance of cloud formation templete


{

AWSTempleteFormationVersion:""
Description:""
Resources:{}
Outputs:{}
}

S3Bucket:{
Type:AWS::S3:Bucket,
Properties:{}
parameters:{}
mapping:{}
DeletionPolicy:""
}

searching in google
awscloudformation userguide cfn bootstrapping (search in google)
aws cloudformation articles and tutorials
cloudformation getting started
aws-cloudformation templetes
github awslabs cfncluster



update stack  so we cannot edit update to same one with different temp.

Resource:
 MyInstance:
  Type:AWS::EC2
  Properties:
   AvailabityZone:



updateing s3 bucket::
without replacement
or with replacement
AccessControl in aws


go to cloud formation then ->select Action ->update sstack then update in cloud formation file

lets learn about tha parms that are common to cloudformation::
tags
permisssion
notification
timeout
rollback or failure


designing of cloud fromation::
cloudformation ->design templete

building blocks::
 Resources:your aws resource declared in templete
 paramerters::dynmic parms in your temp
 mappings:: stataic varible in your temp
 outputs:ref to what you have been created
 conditional:list of condition to perform res
 metadata:

parameters::
type
string,number,	commo delimiter list,List<Type>	,AWS parameter
description
constraints
constraint description(string)


searh aws parameters in cloud formation

if you want to use parameters then use !Ref variablename


ref. parms.
Fn::Ref==>short in yml !Ref

AWS::productname::data type name

optional attribute resources::
depends on::
deletion policies::
metadata::



CLOUD FORMATION MAPPINGS:;

RegionMap:
 us-east-01:
  "44":"ami"
  "45":"ami"
 us-east-02:
  "44":"ami"
  "45":"ami"


accessing value in Fn::FindInMap

Fn::ImportValue

conditionals
Enviroment(dev/test/prod)

conditions:
 logicalId:
  instrinsic function

Fn::And
Fn::If
Fn::Equal
etc

Fn:GetAll

Fn::GetAtt:[logicalNameOfResource,attributeName]
!GetAtt logicalNameOfResource.attributeName


cloudformation metadata::
optional data import and attached to any resource


cloud formation init::

scripts::
cfn-init
cfn-signal
cfn-get-metadata
cfn-hup
 

!Sub (method replacing subsititutation)

cfn-hub.config file


Advance cloud formation stuff::



Troposphere to template creation in python.
github/cloudtools/troposphere

deletion policiy::
delete and retains: of resources(like db and s3)

searching:
custom resources with aws lambda::custom proviosing 

awscloudformation walkthorugh custom resources lambda lookup


best practiciess::

best practices::
horizontal and (services)vertical layers
use cross stack refrecences to ref of vpc and subnets
templetes are env. agonistics so you can do dev/test/prod and across region /accout
no embed cred

use specific parms and cosntrinats
use cfn init
validate templete
dont do anything manually

cost estimation::
github awslabs


aws --profile dev configure set ...

password reset with the help of cli::

crate login profile
aws --profile admin iam create-login-profile --user-name s.cooper --password passwod --password-reset-required 

change your password::
aws --profile admin iam change-password --old-password 

getting access key::
aws --profile admin configure get aws_access_key_id

create new creadintials::
aws --profile admin iam create-access-key --user-name s.cooper

set new keyss::
aws --profile admin configure set aws_access_key_id <new key id>
aws --profile admin configure set aws_secret_access_key <new key id>

manageing network resources::


Amazon vpc::
using vpc

vpc span the region
and subnet per availablity zone

amazon virtual private clouding defence::::
routing::
	route table by default local
network access control list:: state less
security groups:: it applied to instances state full


/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////


/////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
preview of changes::
will show 
resource to be change
scope of change
replacment

network acls:network access control list

review of amazon route 53:
register domain
transfer domain
different of routing methods::
 
DNS::
A record:: alias server 
MX::mail server 
NS:: name server

route 53 is global

managing object storgae::
storing static web content
centralizing log files

amzon simple storgae service::(S3) key value storage
s3 for host static web site
no bucket size

standarize::
dns_endpoint/nameofbucket/key

one way to access s3 bucket via resource based policies::
s2
asqs
ec2 container registry
etc.

enforcing encryption for s3::

cross accout sharing and policy::we are allowed policies to account

suppose:
owning accounts of s3:admin
now create bucket policies for allowed to write log files in this s3
now dev account grant access to allowed for writing


create several s3 in admin accounts::
1:operation 2:config 3:backups

aws --profile admin s3 sync source/ s3://aws-linux-ops/ --exclude "configure/**" --delete



Managing compute resource::

in ec2 virtual machine called an instance

launch 1 to thousands

Diffeernt billing models::
on demand::MSRP 
reserved::
spot::price fluctuate according to demand

key pairs import into ec2 for accessing

manage ec2 roles and profiles

machine name amzon can have unique ids

finding amazon machine using cli

launch instance with aws cli
 capture ami id as env variable
 

suppose we are not passing subnet at the time loading instace(ec2) so amazon assign vpc for it by default an vpc attached with network gateway

open port 22 for our ip address


instance mata data service::
http://169.254.169.254/latest/meta-data
can retreive ::
AMI id
hostname
insatance id
instance type
private ip address

getting instance meta data with curl::

capture ip address of ec2


creating amzon machine image python

 
share one image from one accout to another::
 like we create a image in dev and needs replica on production



creating autoscling group::

autoscaling group resopensible for creating ec2 instances
also there is security group with each ec2.

AWS lambda review::
enviroment clean up with lambda python

Elastic load balancing::
having more then one ec2 and each ec2 inside another vpc
we having higer availablity zone for each so that if one is fail another is open
n/w footprint for load balancer

load balancer listerners::
now having two types of load balancer::
classic(fixed port mapping)::layer 4
applicatoin load balnacer::
layer 7
host name and path based routing
dynamic port mapping


now create load balancer using aws cli::
n/w footprint in each instance also needs of secuirty group
DMZ subnet

managing block storage::
analyzing elastic block store.

ec2 comes with data storage but what when instace is terminating all storeage goes down so for that purpose we used
EBS (elastic block storage)
data indent from instance
only attach one volumn per instance

now have serverl types of volumn ::SSD and HDD


creating ebs volumn:

mounting with aws cli

now attached volumn to ec2

now attached into different file system
like mount var/xvda var/mongo

Manageing database::

review of amzon database services::
amazon aurora ,mysql ,oracle etc

Multi AZ deployment.
automatic failover :: secondary rds provide  by it 

automated backup and manual snapshot

RDS subnet groups::

Amazon Rds db instance with cloud formation

snapshot and cross region copy

Dynamo db::
 no sql data
 ssd backed
 it can also autoscale thorougput

partitioning of table 
shrding of table
indexing
no join

create dynamo db table::


sevic time env url

service partition key


monitoring and logging::
cloud watch and cloud trails for alerm cration

Cloud watch::
 collect matrix
 stored for 2 weeks
 
EC2::
 default 5 min interval
 default 1 min

ELB::
 default 1 min interval

RDS::
 memory,connction,disk

Dynamo DB:
 throughput provisioning

Triggered on breach of threshold
 possible states:: 1:ok 2:alarm 3:insufficent_data

Third party service for trigger alarm:: pagerDuty


Cloud watch logs::
centralizing logging.
configure agent on instance


creating amzon sns topics::


